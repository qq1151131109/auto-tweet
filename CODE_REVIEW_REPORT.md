# ä»£ç å®¡æŸ¥æŠ¥å‘Š

**å®¡æŸ¥æ—¥æœŸ**: 2025-12-11
**é¡¹ç›®**: auto-tweet-generator
**å®¡æŸ¥èŒƒå›´**: æ ¸å¿ƒä»£ç ã€é…ç½®ç³»ç»Ÿã€å·¥å…·æ¨¡å—ã€æµ‹è¯•ä»£ç 

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æ€»ä½“è¯„ä»·: **è‰¯å¥½** â­â­â­â­â˜† (4/5æ˜Ÿ)

æœ¬é¡¹ç›®ä»£ç æ•´ä½“è´¨é‡è¾ƒé«˜,æ¶æ„æ¸…æ™°,ä½†å­˜åœ¨ä¸€äº›å¯ä»¥æ”¹è¿›çš„åœ°æ–¹ã€‚ä»¥ä¸‹æ˜¯ä¸»è¦å‘ç°:

**ä¼˜ç‚¹**:
- âœ… æ¨¡å—åŒ–è®¾è®¡æ¸…æ™°,èŒè´£åˆ†ç¦»åˆç†
- âœ… å¼‚æ­¥å¹¶å‘å®ç°æ­£ç¡®,ä½¿ç”¨äº†åˆç†çš„é™æµæœºåˆ¶
- âœ… JSONè§£æç»Ÿä¸€å¤„ç†,é¿å…äº†ä»£ç é‡å¤
- âœ… é”™è¯¯å¤„ç†è¾ƒå®Œå–„
- âœ… ä»£ç æ³¨é‡Šè¯¦ç»†,ä¿ç•™äº†ComfyUIç²¾è°ƒé€»è¾‘çš„æ ‡æ³¨

**ä¸»è¦é—®é¢˜**:
- âš ï¸ è¿‡å¤šä½¿ç”¨ `sys.path.insert(0, ...)` çš„è·¯å¾„hack
- âš ï¸ å­˜åœ¨å¤§é‡è£¸éœ²çš„ `except:` å—(16ä¸ªæ–‡ä»¶)
- âš ï¸ é…ç½®æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç é—®é¢˜
- âš ï¸ éƒ¨åˆ†æ¨¡å—ç¼ºå°‘ç±»å‹æ³¨è§£
- âš ï¸ æµ‹è¯•è¦†ç›–ç‡ä¸è¶³

---

## ğŸ” è¯¦ç»†é—®é¢˜åˆ†æ

### 1. è·¯å¾„ç®¡ç†é—®é¢˜ (ä¸¥é‡æ€§: âš ï¸ ä¸­ç­‰)

**é—®é¢˜æè¿°**:
å¤šä¸ªæ¨¡å—ä½¿ç”¨ `sys.path.insert(0, ...)` hackæ¥æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ã€‚

**å½±å“çš„æ–‡ä»¶**:
- `core/persona_generator.py` (L15)
- `core/tweet_generator.py` (L13)
- `core/image_generator.py` (L107)
- `main.py` (L20)

**ç¤ºä¾‹ä»£ç **:
```python
# core/persona_generator.py:15
sys.path.insert(0, str(Path(__file__).parent.parent))
```

**ä¸ºä»€ä¹ˆæ˜¯é—®é¢˜**:
1. æ±¡æŸ“å…¨å±€ `sys.path`,å¯èƒ½å¯¼è‡´æ„å¤–çš„æ¨¡å—å¯¼å…¥
2. éš¾ä»¥è°ƒè¯•è·¯å¾„é—®é¢˜
3. ä¸ç¬¦åˆPythonæœ€ä½³å®è·µ
4. åœ¨ä¸åŒç¯å¢ƒ(Docker/æœ¬åœ°/tests)å¯èƒ½è¡¨ç°ä¸ä¸€è‡´

**æ¨èè§£å†³æ–¹æ¡ˆ**:
```python
# æ–¹æ¡ˆ1: ä½¿ç”¨ç›¸å¯¹å¯¼å…¥
from ..utils import llm_client

# æ–¹æ¡ˆ2: è®¾ç½®PYTHONPATHç¯å¢ƒå˜é‡
# export PYTHONPATH=/home/ubuntu/shenglin/auto-tweet-generator:$PYTHONPATH

# æ–¹æ¡ˆ3: ä½¿ç”¨setup.py/pyproject.tomlå®‰è£…ä¸ºå¯ç¼–è¾‘åŒ…
# pip install -e .
```

**ä¼˜å…ˆçº§**: ä¸­ç­‰ (ä¸å½±å“åŠŸèƒ½,ä½†å½±å“å¯ç»´æŠ¤æ€§)

---

### 2. å¼‚å¸¸å¤„ç†ä¸å¤Ÿç²¾ç¡® (ä¸¥é‡æ€§: âš ï¸ ä¸­ç­‰)

**é—®é¢˜æè¿°**:
16ä¸ªæ–‡ä»¶ä¸­å­˜åœ¨è£¸éœ²çš„ `except:` å—,æ•è·æ‰€æœ‰å¼‚å¸¸è€Œä¸åŒºåˆ†ç±»å‹ã€‚

**å½±å“çš„æ–‡ä»¶**:
- `core/image_generator.py`
- `core/image_generator_advanced.py`
- `core/image_generator_advanced_v2.py`
- `tools/datetime_tool.py`
- ä»¥åŠ12ä¸ªlegacyæ–‡ä»¶

**ç¤ºä¾‹ä»£ç **:
```python
# core/image_generator.py:88
try:
    self.pipeline.transformer.set_attention_backend("flash")
    logger.info("   âœ“ ä½¿ç”¨Flash Attention")
except:
    pass
```

**ä¸ºä»€ä¹ˆæ˜¯é—®é¢˜**:
1. å¯èƒ½éšè—é‡è¦çš„é”™è¯¯(å¦‚ `KeyboardInterrupt`)
2. éš¾ä»¥è°ƒè¯•,ä¸çŸ¥é“å…·ä½“ä»€ä¹ˆé”™è¯¯è¢«æ•è·
3. è¿åPythonæœ€ä½³å®è·µ(PEP 8)

**æ¨èè§£å†³æ–¹æ¡ˆ**:
```python
# ä¿®æ”¹å‰
try:
    self.pipeline.transformer.set_attention_backend("flash")
except:
    pass

# ä¿®æ”¹å - æ˜ç¡®æŒ‡å®šå¼‚å¸¸ç±»å‹
try:
    self.pipeline.transformer.set_attention_backend("flash")
    logger.info("   âœ“ ä½¿ç”¨Flash Attention")
except (AttributeError, RuntimeError) as e:
    logger.warning(f"   Flash Attentionä¸å¯ç”¨: {e}")
```

**ä¼˜å…ˆçº§**: ä¸­ç­‰ (å½±å“è°ƒè¯•ä½“éªŒ)

---

### 3. LoRAå¸è½½é€»è¾‘å¯èƒ½ä¸å®Œæ•´ (ä¸¥é‡æ€§: âš ï¸ ä¸­ç­‰)

**é—®é¢˜æè¿°**:
`core/image_generator.py` ä¸­çš„LoRAåŠ è½½/å¸è½½é€»è¾‘å¯èƒ½å¯¼è‡´èµ„æºæ³„æ¼ã€‚

**ç›¸å…³ä»£ç ** (L186-241):
```python
def generate_image(self, ...):
    # åŠ è½½LoRA
    if lora_path:
        self.load_lora(lora_path, lora_strength)

    # ç”Ÿæˆå›¾ç‰‡
    result = self.pipeline(...)

    # å¸è½½LoRA
    if lora_path:
        self.unload_lora()  # å¦‚æœç”Ÿæˆè¿‡ç¨‹æŠ›å‡ºå¼‚å¸¸,è¿™é‡Œä¸ä¼šè¢«æ‰§è¡Œ
```

**ä¸ºä»€ä¹ˆæ˜¯é—®é¢˜**:
å¦‚æœ `self.pipeline(...)` æŠ›å‡ºå¼‚å¸¸,`unload_lora()` æ°¸è¿œä¸ä¼šè¢«è°ƒç”¨,å¯¼è‡´:
1. LoRAæƒé‡æ®‹ç•™åœ¨å†…å­˜ä¸­
2. ä¸‹ä¸€æ¬¡ç”Ÿæˆå¯èƒ½ä½¿ç”¨é”™è¯¯çš„LoRA
3. å†…å­˜æ³„æ¼

**æ¨èè§£å†³æ–¹æ¡ˆ**:
```python
def generate_image(self, ...):
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿æ¸…ç†
    lora_loaded = False
    try:
        if lora_path:
            self.load_lora(lora_path, lora_strength)
            lora_loaded = True

        # ç”Ÿæˆå›¾ç‰‡
        if self.use_diffusers:
            result = self.pipeline(...)
            image = result.images[0]
        else:
            ...

        return image

    finally:
        # ç¡®ä¿LoRAä¸€å®šè¢«å¸è½½
        if lora_loaded:
            self.unload_lora()
```

**ä¼˜å…ˆçº§**: é«˜ (å¯èƒ½å½±å“ç”Ÿæˆè´¨é‡å’Œå†…å­˜)

---

### 4. æ¨æ–‡é•¿åº¦æ£€æŸ¥é€»è¾‘é‡å¤ (ä¸¥é‡æ€§: âš ï¸ ä½)

**é—®é¢˜æè¿°**:
`core/tweet_generator.py` ä¸­æœ‰ä¸¤ä¸ªå‡ ä¹ç›¸åŒçš„æ¨æ–‡é•¿åº¦æ£€æŸ¥ä»£ç å—ã€‚

**ç›¸å…³ä»£ç ** (L66-78 å’Œ L124-136):
```python
# generate_single_tweet() å’Œ generate_from_spec() éƒ½æœ‰ç›¸åŒçš„ä»£ç :
tweet_text = result.get("tweet_text", "")
max_retries = 3
retry_count = 0

while len(tweet_text) > 270 and retry_count < max_retries:
    print(f"âš ï¸ æ¨æ–‡è¶…é•¿ ({len(tweet_text)}å­—ç¬¦), è§¦å‘æ”¹å†™ (ç¬¬{retry_count+1}æ¬¡)")
    tweet_text = await self._rewrite_tweet(tweet_text, persona)
    result["tweet_text"] = tweet_text
    retry_count += 1

if len(tweet_text) > 270:
    print(f"âš ï¸ è­¦å‘Š: æ¨æ–‡åœ¨{max_retries}æ¬¡æ”¹å†™åä»è¶…è¿‡270å­—ç¬¦ ({len(tweet_text)}å­—ç¬¦)")
```

**æ¨èè§£å†³æ–¹æ¡ˆ**:
```python
# æå–ä¸ºç‹¬ç«‹æ–¹æ³•
async def _ensure_tweet_length(
    self,
    tweet_text: str,
    persona: Dict,
    max_length: int = 270,
    max_retries: int = 3
) -> str:
    """ç¡®ä¿æ¨æ–‡é•¿åº¦åœ¨é™åˆ¶å†…,å¿…è¦æ—¶æ”¹å†™"""
    retry_count = 0

    while len(tweet_text) > max_length and retry_count < max_retries:
        print(f"âš ï¸ æ¨æ–‡è¶…é•¿ ({len(tweet_text)}å­—ç¬¦), è§¦å‘æ”¹å†™ (ç¬¬{retry_count+1}æ¬¡)")
        tweet_text = await self._rewrite_tweet(tweet_text, persona)
        retry_count += 1

    if len(tweet_text) > max_length:
        print(f"âš ï¸ è­¦å‘Š: æ¨æ–‡åœ¨{max_retries}æ¬¡æ”¹å†™åä»è¶…è¿‡{max_length}å­—ç¬¦ ({len(tweet_text)}å­—ç¬¦)")

    return tweet_text

# ä½¿ç”¨
result["tweet_text"] = await self._ensure_tweet_length(result["tweet_text"], persona)
```

**ä¼˜å…ˆçº§**: ä½ (ä¸å½±å“åŠŸèƒ½,ä½†æå‡å¯ç»´æŠ¤æ€§)

---

### 5. é…ç½®æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç  (ä¸¥é‡æ€§: âš ï¸ ä¸­ç­‰)

**é—®é¢˜æè¿°**:
å¤šå¤„ä»£ç ç¡¬ç¼–ç äº†é…ç½®æ–‡ä»¶è·¯å¾„,éš¾ä»¥åœ¨ä¸åŒç¯å¢ƒä¸­è¿è¡Œã€‚

**ç¤ºä¾‹**:
```python
# core/image_generator.py:733
from config.image_config import load_image_config
config = load_image_config()  # å†…éƒ¨ç¡¬ç¼–ç  "config/image_generation.yaml"
```

**å½±å“**:
1. æµ‹è¯•æ—¶éš¾ä»¥ä½¿ç”¨æµ‹è¯•é…ç½®
2. Dockeréƒ¨ç½²æ—¶è·¯å¾„å¯èƒ½ä¸æ­£ç¡®
3. å¤šç¯å¢ƒé…ç½®åˆ‡æ¢å›°éš¾

**æ¨èè§£å†³æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ç¯å¢ƒå˜é‡æ”¯æŒé…ç½®è·¯å¾„
import os
from pathlib import Path

def load_image_config(config_path: Optional[str] = None) -> Dict:
    """åŠ è½½å›¾ç‰‡ç”Ÿæˆé…ç½®

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„,å¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„æˆ–ç¯å¢ƒå˜é‡
    """
    if config_path is None:
        config_path = os.getenv(
            'IMAGE_CONFIG_PATH',
            'config/image_generation.yaml'
        )

    config_path = Path(config_path)
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)
```

**ä¼˜å…ˆçº§**: ä¸­ç­‰ (å½±å“å¯æµ‹è¯•æ€§å’Œéƒ¨ç½²çµæ´»æ€§)

---

### 6. LLMå®¢æˆ·ç«¯é‡è¯•é€»è¾‘ç¼ºå¤± (ä¸¥é‡æ€§: âš ï¸ é«˜)

**é—®é¢˜æè¿°**:
`utils/llm_client.py` ä¸­ä½¿ç”¨äº†OpenAI SDKçš„ `max_retries=3`,ä½†å¯¹äºaiohttpæ¨¡å¼æ²¡æœ‰é‡è¯•é€»è¾‘ã€‚

**ç›¸å…³ä»£ç ** (L89-121):
```python
async def _generate_with_aiohttp(self, ...):
    async with aiohttp.ClientSession() as session:
        async with session.post(...) as resp:
            if resp.status != 200:
                error_text = await resp.text()
                raise RuntimeError(f"LLM API é”™è¯¯ {resp.status}: {error_text}")
            # æ²¡æœ‰é‡è¯•!å¦‚æœç½‘ç»œæŠ–åŠ¨,ç›´æ¥å¤±è´¥
```

**ä¸ºä»€ä¹ˆæ˜¯é—®é¢˜**:
1. ç½‘ç»œç¬æ—¶æ•…éšœä¼šå¯¼è‡´æ•´ä¸ªæ‰¹æ¬¡å¤±è´¥
2. 429 (rate limit)é”™è¯¯éœ€è¦æŒ‡æ•°é€€é¿é‡è¯•
3. ä¸ä¸€è‡´:SDKæ¨¡å¼æœ‰é‡è¯•,aiohttpæ¨¡å¼æ²¡æœ‰

**æ¨èè§£å†³æ–¹æ¡ˆ**:
```python
async def _generate_with_aiohttp(self, messages, temperature, max_tokens, timeout):
    """å¸¦é‡è¯•çš„aiohttpè°ƒç”¨"""
    max_retries = 3
    base_delay = 1  # ç§’

    for attempt in range(max_retries):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(...) as resp:
                    if resp.status == 429:  # Rate limit
                        if attempt < max_retries - 1:
                            delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                            logger.warning(f"Rate limited, retrying in {delay}s...")
                            await asyncio.sleep(delay)
                            continue

                    if resp.status != 200:
                        error_text = await resp.text()
                        raise RuntimeError(f"LLM API é”™è¯¯ {resp.status}: {error_text}")

                    data = await resp.json()
                    return data["choices"][0]["message"]["content"]

        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                logger.warning(f"Request failed: {e}, retrying in {delay}s...")
                await asyncio.sleep(delay)
            else:
                raise
```

**ä¼˜å…ˆçº§**: é«˜ (å½±å“ç”Ÿäº§å¯é æ€§)

---

### 7. æ—¥å¿—é…ç½®æ··ä¹± (ä¸¥é‡æ€§: âš ï¸ ä½)

**é—®é¢˜æè¿°**:
ä¸åŒæ¨¡å—ä½¿ç”¨ä¸åŒçš„æ—¥å¿—æ–¹å¼:
- `main.py` ä½¿ç”¨ `logging.basicConfig`
- `core/image_generator.py` ä½¿ç”¨ `logger = logging.getLogger(__name__)`
- `core/tweet_generator.py` ä½¿ç”¨ `print()` è¾“å‡º

**ç¤ºä¾‹**:
```python
# core/tweet_generator.py:71
print(f"âš ï¸ æ¨æ–‡è¶…é•¿ ({len(tweet_text)}å­—ç¬¦), è§¦å‘æ”¹å†™ (ç¬¬{retry_count+1}æ¬¡)")

# åº”è¯¥ä½¿ç”¨logger
logger.warning(f"æ¨æ–‡è¶…é•¿ ({len(tweet_text)}å­—ç¬¦), è§¦å‘æ”¹å†™ (ç¬¬{retry_count+1}æ¬¡)")
```

**æ¨èè§£å†³æ–¹æ¡ˆ**:
1. ç»Ÿä¸€ä½¿ç”¨ `logging` æ¨¡å—
2. åˆ›å»ºä¸­å¿ƒåŒ–çš„æ—¥å¿—é…ç½®æ–‡ä»¶
3. å°†æ‰€æœ‰ `print()` æ›¿æ¢ä¸º `logger.info()` / `logger.warning()`

**ä¼˜å…ˆçº§**: ä½ (ä¸å½±å“åŠŸèƒ½,ä½†å½±å“æ—¥å¿—ç®¡ç†)

---

### 8. ç±»å‹æ³¨è§£ç¼ºå¤± (ä¸¥é‡æ€§: âš ï¸ ä½)

**é—®é¢˜æè¿°**:
è®¸å¤šå‡½æ•°ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£,å½±å“IDEè‡ªåŠ¨è¡¥å…¨å’Œç±»å‹æ£€æŸ¥ã€‚

**ç¤ºä¾‹**:
```python
# core/persona_generator.py:127
def _image_to_base64(self, image_path: str) -> str:  # âœ… æœ‰è¿”å›ç±»å‹
    ...

# core/persona_generator.py:560
def _parse_json_response(self, response: str) -> Dict:  # âœ… æœ‰è¿”å›ç±»å‹
    ...

# core/tweet_generator.py:684
def _parse_response(self, response: str, calendar_plan: Dict, persona: Dict) -> Dict:  # âœ… æœ‰è¿”å›ç±»å‹
    ...
```

å¤§éƒ¨åˆ†æ ¸å¿ƒå‡½æ•°å·²æœ‰ç±»å‹æ³¨è§£,ä½†ä¸€äº›è¾…åŠ©å‡½æ•°ç¼ºå¤±ã€‚

**æ¨è**:
- ç»§ç»­ä¿æŒç±»å‹æ³¨è§£
- å¯¹æ–°å‡½æ•°æ·»åŠ å®Œæ•´çš„ç±»å‹æç¤º
- è€ƒè™‘ä½¿ç”¨ `mypy` è¿›è¡Œé™æ€ç±»å‹æ£€æŸ¥

**ä¼˜å…ˆçº§**: ä½ (ä¸å½±å“è¿è¡Œ,ä½†æå‡å¼€å‘ä½“éªŒ)

---

## ğŸ“Š ä»£ç è´¨é‡ç»Ÿè®¡

| æŒ‡æ ‡ | æ•°å€¼ | è¯„çº§ |
|------|------|------|
| **è¯­æ³•é”™è¯¯** | 0 | âœ… ä¼˜ç§€ |
| **æœªä½¿ç”¨çš„import \*** | 0 | âœ… ä¼˜ç§€ |
| **è£¸éœ²çš„exceptå—** | 16ä¸ªæ–‡ä»¶ | âš ï¸ éœ€æ”¹è¿› |
| **sys.path hack** | 4ä¸ªæ ¸å¿ƒæ–‡ä»¶ | âš ï¸ éœ€æ”¹è¿› |
| **ä»£ç é‡å¤** | å°‘é‡ | â­ è‰¯å¥½ |
| **æ³¨é‡Šè¦†ç›–** | é«˜ | âœ… ä¼˜ç§€ |
| **ç±»å‹æ³¨è§£** | ä¸­ç­‰ | â­ è‰¯å¥½ |
| **æµ‹è¯•è¦†ç›–** | 16ä¸ªæµ‹è¯•è„šæœ¬ | â­ è‰¯å¥½ |

---

## âœ… åšå¾—å¥½çš„åœ°æ–¹

### 1. å¼‚æ­¥å¹¶å‘è®¾è®¡ä¼˜ç§€

`core/persona_generator.py:82-111` ä¸­ä½¿ç”¨äº†æ­£ç¡®çš„å¼‚æ­¥å¹¶å‘æ¨¡å¼:

```python
# Stage 4-7: å¹¶å‘ç”Ÿæˆ
stage_4_task = self._generate_social_network(...)
stage_5_task = self._generate_authenticity(...)
stage_6_task = self._generate_visual_profile(...)
stage_7_task = self._generate_character_book(...)

# å¹¶å‘æ‰§è¡Œ
results = await asyncio.gather(
    stage_4_task, stage_5_task, stage_6_task, stage_7_task,
    return_exceptions=True  # âœ… æ­£ç¡®ä½¿ç”¨return_exceptions
)

# æ£€æŸ¥é”™è¯¯
for i, result in enumerate(results, start=4):
    if isinstance(result, Exception):
        print(f"  âš ï¸  Stage {i} failed: {result}")
```

**ä¼˜ç‚¹**:
- âœ… æ­£ç¡®ä½¿ç”¨ `asyncio.gather` å¹¶å‘æ‰§è¡Œç‹¬ç«‹ä»»åŠ¡
- âœ… ä½¿ç”¨ `return_exceptions=True` é¿å…ä¸€ä¸ªå¤±è´¥å¯¼è‡´å…¨éƒ¨å¤±è´¥
- âœ… æ˜¾å¼æ£€æŸ¥å¼‚å¸¸ç»“æœ

### 2. JSONè§£æç»Ÿä¸€åŒ–å¤„ç†

`utils/json_parser.py` æä¾›äº†ç»Ÿä¸€çš„JSONè§£æé€»è¾‘:

**ä¼˜ç‚¹**:
- âœ… é¿å…äº†ä»£ç é‡å¤(åŸå…ˆåˆ†æ•£åœ¨å¤šä¸ªæ¨¡å—ä¸­)
- âœ… æä¾›äº†fallbackç­–ç•¥(Markdownæ¸…ç†ã€å¼•å·è§„èŒƒåŒ–ã€æˆªæ–­ä¿®å¤)
- âœ… é”™è¯¯ä¿¡æ¯è¯¦ç»†,ä¾¿äºè°ƒè¯•

### 3. é…ç½®ç³»ç»Ÿæ¸…æ™°

åŒé…ç½®æ–‡ä»¶è®¾è®¡åˆç†:
- `generation_config.yaml` - LLMå‚æ•°
- `image_generation.yaml` - å›¾ç‰‡ç”Ÿæˆå‚æ•°

**ä¼˜ç‚¹**:
- âœ… èŒè´£åˆ†ç¦»æ¸…æ™°
- âœ… æ”¯æŒYAMLæ ¼å¼,æ˜“äºäººå·¥ç¼–è¾‘
- âœ… æœ‰é¢„è®¾(preset)æ”¯æŒå¿«é€Ÿåˆ‡æ¢

### 4. å®‰å…¨çš„å­—å…¸è®¿é—®

`core/image_generator.py:335-348` ä½¿ç”¨äº† `.get()` æ–¹æ³•å®‰å…¨è®¿é—®:

```python
# å®‰å…¨è®¿é—®,é¿å…KeyError
positive_prompt = img_gen.get("positive_prompt", "")
negative_prompt = img_gen.get("negative_prompt", "")
lora_params = img_gen.get("lora_params", {})
gen_params = img_gen.get("generation_params", {})
```

### 5. è¯¦ç»†çš„æ–‡æ¡£æ³¨é‡Š

å¤šæ•°å‡½æ•°æœ‰æ¸…æ™°çš„docstring,ä¾‹å¦‚:

```python
async def generate_from_image(
    self,
    image_path: str,
    nsfw_level: str = "enabled",
    language: str = "English",
    ...
) -> Dict:
    """
    ä»å›¾ç‰‡ç”Ÿæˆå®Œæ•´äººè®¾(å¤šé˜¶æ®µæµç¨‹)
    å®Œå…¨ä¿ç•™ComfyUIçš„PersonaCoreGeneratoré€»è¾‘

    Args:
        image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
        nsfw_level: "disabled" æˆ– "enabled"
        ...

    Returns:
        å®Œæ•´çš„äººè®¾JSON(SillyTavern Character Card V2æ ¼å¼)
    """
```

---

## ğŸ¯ ä¼˜å…ˆä¿®å¤å»ºè®®

æŒ‰ä¼˜å…ˆçº§æ’åº:

### P0 - ç«‹å³ä¿®å¤ (å½±å“åŠŸèƒ½æ­£ç¡®æ€§)

1. **LoRAå¸è½½é€»è¾‘** - ä½¿ç”¨try/finallyç¡®ä¿æ¸…ç†
2. **LLMé‡è¯•é€»è¾‘** - æ·»åŠ æŒ‡æ•°é€€é¿é‡è¯•

### P1 - çŸ­æœŸä¿®å¤ (å½±å“ç¨³å®šæ€§)

3. **å¼‚å¸¸å¤„ç†ç²¾ç¡®åŒ–** - å°†è£¸éœ²çš„ `except:` æ”¹ä¸ºå…·ä½“å¼‚å¸¸ç±»å‹
4. **é…ç½®æ–‡ä»¶è·¯å¾„** - æ”¯æŒç¯å¢ƒå˜é‡é…ç½®è·¯å¾„

### P2 - ä¸­æœŸæ”¹è¿› (æå‡å¯ç»´æŠ¤æ€§)

5. **è·¯å¾„ç®¡ç†** - ä½¿ç”¨ç›¸å¯¹å¯¼å…¥æˆ–å®‰è£…ä¸ºåŒ…
6. **ä»£ç é‡å¤** - æå–æ¨æ–‡é•¿åº¦æ£€æŸ¥ä¸ºç‹¬ç«‹æ–¹æ³•
7. **æ—¥å¿—ç»Ÿä¸€** - å°† `print()` æ›¿æ¢ä¸º `logger`

### P3 - é•¿æœŸä¼˜åŒ– (æå‡å¼€å‘ä½“éªŒ)

8. **ç±»å‹æ³¨è§£** - å®Œå–„ç±»å‹æç¤º
9. **æµ‹è¯•è¦†ç›–** - å¢åŠ å•å…ƒæµ‹è¯•
10. **æ–‡æ¡£è¡¥å……** - æ·»åŠ APIæ–‡æ¡£

---

## ğŸ”§ å…·ä½“ä¿®å¤æ­¥éª¤

### æ­¥éª¤1: ä¿®å¤LoRAæ¸…ç†é€»è¾‘

**æ–‡ä»¶**: `core/image_generator.py`

```python
# åœ¨ generate_image() æ–¹æ³•ä¸­:
def generate_image(self, ...) -> Image.Image:
    lora_loaded = False
    try:
        # ç”Ÿæˆç§å­
        if seed is None:
            seed = torch.randint(0, 2**63 - 1, (1,)).item()

        # åŠ è½½LoRA
        if lora_path:
            self.load_lora(lora_path, lora_strength)
            lora_loaded = True

        # åˆ›å»ºgenerator
        generator = torch.Generator(self.device).manual_seed(seed)

        if self.use_diffusers:
            result = self.pipeline(...)
            image = result.images[0]
        else:
            ...

        return image

    finally:
        # ç¡®ä¿LoRAè¢«å¸è½½
        if lora_loaded and self.use_diffusers:
            try:
                self.unload_lora()
            except Exception as e:
                logger.warning(f"LoRAå¸è½½å¤±è´¥: {e}")
```

### æ­¥éª¤2: æ·»åŠ LLMé‡è¯•é€»è¾‘

**æ–‡ä»¶**: `utils/llm_client.py`

åœ¨ `_generate_with_aiohttp()` æ–¹æ³•ä¸­æ·»åŠ é‡è¯•:

```python
async def _generate_with_aiohttp(
    self,
    messages: List[Dict],
    temperature: float,
    max_tokens: int,
    timeout: int
) -> str:
    """ä½¿ç”¨aiohttpå¼‚æ­¥è°ƒç”¨(å¸¦é‡è¯•)"""
    max_retries = 3
    base_delay = 1

    for attempt in range(max_retries):
        try:
            url = f"{self.api_base}/chat/completions"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            }

            async with aiohttp.ClientSession() as session:
                async with session.post(
                    url,
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=timeout)
                ) as resp:
                    # å¤„ç†rate limit
                    if resp.status == 429 and attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt)
                        logger.warning(f"Rate limit hit, retrying in {delay}s...")
                        await asyncio.sleep(delay)
                        continue

                    if resp.status != 200:
                        error_text = await resp.text()
                        raise RuntimeError(f"LLM API é”™è¯¯ {resp.status}: {error_text}")

                    data = await resp.json()
                    return data["choices"][0]["message"]["content"]

        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                logger.warning(f"Request failed: {e}, retrying in {delay}s...")
                await asyncio.sleep(delay)
            else:
                raise RuntimeError(f"LLMè°ƒç”¨å¤±è´¥(é‡è¯•{max_retries}æ¬¡): {e}")

    raise RuntimeError("LLMè°ƒç”¨å¤±è´¥:è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°")
```

### æ­¥éª¤3: ä¿®å¤è£¸éœ²å¼‚å¸¸

**ç¤ºä¾‹**: `core/image_generator.py:85-89`

```python
# ä¿®æ”¹å‰
try:
    self.pipeline.transformer.set_attention_backend("flash")
    logger.info("   âœ“ ä½¿ç”¨Flash Attention")
except:
    pass

# ä¿®æ”¹å
try:
    self.pipeline.transformer.set_attention_backend("flash")
    logger.info("   âœ“ ä½¿ç”¨Flash Attention")
except (AttributeError, RuntimeError, ValueError) as e:
    logger.debug(f"   Flash Attentionä¸å¯ç”¨: {e}")
```

### æ­¥éª¤4: æå–é‡å¤ä»£ç 

**æ–‡ä»¶**: `core/tweet_generator.py`

```python
# åœ¨ StandaloneTweetGenerator ç±»ä¸­æ·»åŠ æ–°æ–¹æ³•:
async def _ensure_tweet_length(
    self,
    tweet_text: str,
    persona: Dict,
    max_length: int = 270,
    max_retries: int = 3
) -> str:
    """
    ç¡®ä¿æ¨æ–‡é•¿åº¦åœ¨é™åˆ¶å†…,å¿…è¦æ—¶è‡ªåŠ¨æ”¹å†™

    Args:
        tweet_text: åŸå§‹æ¨æ–‡æ–‡æœ¬
        persona: äººè®¾JSON
        max_length: æœ€å¤§é•¿åº¦é™åˆ¶
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        ç¬¦åˆé•¿åº¦è¦æ±‚çš„æ¨æ–‡æ–‡æœ¬
    """
    retry_count = 0

    while len(tweet_text) > max_length and retry_count < max_retries:
        logger.warning(
            f"æ¨æ–‡è¶…é•¿ ({len(tweet_text)}å­—ç¬¦), "
            f"è§¦å‘æ”¹å†™ (ç¬¬{retry_count+1}æ¬¡)"
        )
        tweet_text = await self._rewrite_tweet(tweet_text, persona)
        retry_count += 1

    if len(tweet_text) > max_length:
        logger.warning(
            f"æ¨æ–‡åœ¨{max_retries}æ¬¡æ”¹å†™åä»è¶…è¿‡{max_length}å­—ç¬¦ "
            f"({len(tweet_text)}å­—ç¬¦)"
        )

    return tweet_text

# ç„¶ååœ¨ generate_single_tweet() å’Œ generate_from_spec() ä¸­:
# åˆ é™¤é‡å¤çš„ä»£ç å—,æ›¿æ¢ä¸º:
result["tweet_text"] = await self._ensure_tweet_length(
    result["tweet_text"],
    persona
)
```

---

## ğŸ“ æµ‹è¯•å»ºè®®

å½“å‰æµ‹è¯•è¦†ç›–æƒ…å†µ:
- âœ… 16ä¸ªæµ‹è¯•è„šæœ¬åœ¨ `tests/scripts/`
- âš ï¸ ç¼ºå°‘å•å…ƒæµ‹è¯•æ¡†æ¶(pytest)
- âš ï¸ ç¼ºå°‘CI/CDé›†æˆ

**å»ºè®®æ·»åŠ **:

1. **å•å…ƒæµ‹è¯•** (ä½¿ç”¨pytest):
```bash
tests/
  unit/
    test_json_parser.py       # JSONè§£æé€»è¾‘
    test_llm_client.py         # LLMå®¢æˆ·ç«¯(mock API)
    test_persona_generator.py  # äººè®¾ç”Ÿæˆé€»è¾‘
    test_tweet_generator.py    # æ¨æ–‡ç”Ÿæˆé€»è¾‘
```

2. **é›†æˆæµ‹è¯•**:
```bash
tests/
  integration/
    test_e2e_persona_to_images.py  # ç«¯åˆ°ç«¯æµ‹è¯•
    test_batch_generation.py       # æ‰¹é‡ç”Ÿæˆæµ‹è¯•
```

3. **æ·»åŠ pytest.ini**:
```ini
[pytest]
testpaths = tests/unit tests/integration
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts = -v --cov=core --cov=utils --cov-report=html
```

---

## ğŸ“ æœ€ä½³å®è·µå»ºè®®

### 1. ä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†é…ç½®

```python
# config/settings.py ä¸­åº”è¯¥:
import os
from pathlib import Path

# æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
BASE_DIR = Path(os.getenv('PROJECT_ROOT', Path(__file__).parent.parent))
IMAGE_CONFIG_PATH = os.getenv('IMAGE_CONFIG_PATH', BASE_DIR / 'config/image_generation.yaml')
GENERATION_CONFIG_PATH = os.getenv('GENERATION_CONFIG_PATH', BASE_DIR / 'generation_config.yaml')
```

### 2. æ·»åŠ setup.pyæ”¯æŒåŒ…å®‰è£…

```python
# setup.py
from setuptools import setup, find_packages

setup(
    name="auto-tweet-generator",
    version="1.0.0",
    packages=find_packages(),
    install_requires=[
        "torch>=2.0.0",
        "diffusers>=0.21.0",
        "openai>=1.0.0",
        "aiohttp>=3.9.0",
        "pyyaml>=6.0",
        "pillow>=10.0.0",
        "python-dotenv>=1.0.0",
    ],
    extras_require={
        "dev": ["pytest>=7.0.0", "pytest-cov>=4.0.0", "black>=23.0.0"],
    },
)
```

ç„¶åå¯ä»¥:
```bash
pip install -e .  # å¯ç¼–è¾‘å®‰è£…
# ä¹‹åå°±å¯ä»¥ç›´æ¥ from core.persona_generator import PersonaGenerator
```

### 3. ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨

å¯¹äºéœ€è¦èµ„æºæ¸…ç†çš„æ“ä½œ,ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨:

```python
from contextlib import contextmanager

@contextmanager
def lora_context(self, lora_path: str, strength: float):
    """LoRAä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    try:
        if lora_path:
            self.load_lora(lora_path, strength)
        yield
    finally:
        if lora_path:
            self.unload_lora()

# ä½¿ç”¨
with self.lora_context(lora_path, lora_strength):
    image = self.pipeline(...)
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡ç”Ÿæˆæ—¶çš„è¿æ¥æ± å¤ç”¨

å½“å‰ `utils/llm_client.py` æ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°çš„session:

```python
# ç°æœ‰ä»£ç (L109)
async with aiohttp.ClientSession() as session:
    async with session.post(...) as resp:
        ...
```

**ä¼˜åŒ–å»ºè®®**:
```python
class AsyncLLMClient:
    def __init__(self, ...):
        ...
        self._session = None

    async def __aenter__(self):
        self._session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, *args):
        if self._session:
            await self._session.close()

    async def generate(self, ...):
        if self._session is None:
            async with aiohttp.ClientSession() as session:
                return await self._do_generate(session, ...)
        else:
            return await self._do_generate(self._session, ...)
```

### 2. ç¼“å­˜LoRAæ¨¡å‹

å¦‚æœå¤šä¸ªç”Ÿæˆä»»åŠ¡ä½¿ç”¨ç›¸åŒLoRA,å¯ä»¥ç¼“å­˜é¿å…é‡å¤åŠ è½½:

```python
class ZImageGenerator:
    def __init__(self, ...):
        ...
        self._lora_cache = {}  # {lora_path: (weights, strength)}

    def load_lora(self, lora_path: str, strength: float):
        cache_key = (lora_path, strength)
        if cache_key in self._lora_cache:
            logger.info(f"ä½¿ç”¨ç¼“å­˜çš„LoRA: {lora_path}")
            return

        # æ­£å¸¸åŠ è½½...
        self._lora_cache[cache_key] = True
```

---

## æ€»ç»“

æœ¬é¡¹ç›®ä»£ç è´¨é‡æ€»ä½“è‰¯å¥½,ä¸»è¦ä¼˜åŠ¿åœ¨äº:
- âœ… å¼‚æ­¥å¹¶å‘è®¾è®¡åˆç†
- âœ… æ¨¡å—åŒ–æ¸…æ™°
- âœ… é”™è¯¯å¤„ç†åŸºæœ¬å®Œå–„
- âœ… æ³¨é‡Šè¯¦ç»†

ä¸»è¦æ”¹è¿›æ–¹å‘:
1. ğŸ”§ ä¿®å¤LoRAæ¸…ç†é€»è¾‘(ä½¿ç”¨try/finally)
2. ğŸ”§ æ·»åŠ LLMé‡è¯•æœºåˆ¶(æŒ‡æ•°é€€é¿)
3. ğŸ”§ ç²¾ç¡®åŒ–å¼‚å¸¸å¤„ç†(é¿å…è£¸éœ²except)
4. ğŸ”§ æ”¹å–„è·¯å¾„ç®¡ç†(ä½¿ç”¨ç›¸å¯¹å¯¼å…¥æˆ–åŒ…å®‰è£…)
5. ğŸ”§ ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ(æ›¿æ¢printä¸ºlogger)

å»ºè®®ä¼˜å…ˆä¿®å¤ P0 å’Œ P1 çº§åˆ«çš„é—®é¢˜,ä»¥æå‡ç³»ç»Ÿç¨³å®šæ€§å’Œå¯é æ€§ã€‚

---

**å®¡æŸ¥äºº**: Claude Code
**å®¡æŸ¥æ—¥æœŸ**: 2025-12-11
**é¡¹ç›®ç‰ˆæœ¬**: v1.0
**ä¸‹æ¬¡å®¡æŸ¥å»ºè®®**: ä¿®å¤ä¸Šè¿°é—®é¢˜å2å‘¨

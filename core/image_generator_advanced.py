"""
Z-Image é«˜çº§å›¾ç‰‡ç”Ÿæˆå™¨
åŸºäº ComfyUI workflow/zimage-121101.json çš„ä¼˜åŒ–æ–¹æ¡ˆ

æ ¸å¿ƒç‰¹æ€§ï¼š
1. ä¸‰é˜¶æ®µæ¸è¿›å¼ç”Ÿæˆï¼ˆä½åˆ†è¾¨ç‡ â†’ ä¸­åˆ†è¾¨ç‡ â†’ é«˜åˆ†è¾¨ç‡ï¼‰
2. Trigger Word æ”¯æŒï¼ˆLoRA ä¸“å±è§¦å‘è¯ï¼‰
3. ä¸­æ–‡ Negative Prompt æ”¯æŒ
4. å¤šç§ Sampler å’Œ Scheduler ç­–ç•¥
"""
import sys
from pathlib import Path
from typing import Dict, Optional, List, Tuple
from datetime import datetime
import torch
from PIL import Image
import logging

logger = logging.getLogger(__name__)


class ZImageGeneratorAdvanced:
    """
    Z-Image é«˜çº§å›¾ç‰‡ç”Ÿæˆå™¨ - ä¸‰é˜¶æ®µæ¸è¿›å¼ç”Ÿæˆ

    åŸºäº ComfyUI å·¥ä½œæµçš„ä¼˜åŒ–æ–¹æ¡ˆï¼Œä½¿ç”¨ img2img æ¨¡æ‹Ÿ latent upscale
    """

    def __init__(
        self,
        model_path: str = "Z-Image/ckpts/Z-Image-Turbo",
        device: str = None,
        dtype: torch.dtype = torch.bfloat16,
        compile: bool = False,
    ):
        """
        åˆå§‹åŒ– Z-Image é«˜çº§ç”Ÿæˆå™¨

        Args:
            model_path: Z-Image æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ï¼ˆcuda/cpu/mps/None=è‡ªåŠ¨ï¼‰
            dtype: æ•°æ®ç±»å‹ï¼ˆé»˜è®¤bfloat16ï¼‰
            compile: æ˜¯å¦ç¼–è¯‘æ¨¡å‹ï¼ˆé»˜è®¤Falseï¼‰
        """
        # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        if device is None:
            if torch.cuda.is_available():
                device = "cuda"
            elif torch.backends.mps.is_available():
                device = "mps"
            else:
                device = "cpu"

        self.device = device
        self.dtype = dtype

        logger.info(f"ğŸ”§ åˆå§‹åŒ– ZImageGeneratorAdvanced (ä¸‰é˜¶æ®µæ¸è¿›å¼ç”Ÿæˆ)")
        logger.info(f"   æ¨¡å‹: {model_path}")
        logger.info(f"   è®¾å¤‡: {device}")
        logger.info(f"   ç±»å‹: {dtype}")

        self._init_pipeline(model_path, device, dtype, compile)

        logger.info(f"   âœ“ æ¨¡å‹åŠ è½½å®Œæˆ\n")

    def _init_pipeline(self, model_path: str, device: str, dtype: torch.dtype, compile: bool):
        """åˆå§‹åŒ– Diffusers pipeline"""
        try:
            from diffusers import ZImagePipeline

            logger.info("   åŠ è½½ ZImagePipeline...")
            self.pipeline = ZImagePipeline.from_pretrained(
                model_path,
                torch_dtype=dtype,
                low_cpu_mem_usage=False
            )
            self.pipeline.to(device)

            # å¯é€‰ï¼šè®¾ç½® attention backend
            if hasattr(self.pipeline.transformer, 'set_attention_backend'):
                try:
                    self.pipeline.transformer.set_attention_backend("flash")
                    logger.info("   âœ“ ä½¿ç”¨ Flash Attention")
                except:
                    pass

            # å¯é€‰ï¼šç¼–è¯‘æ¨¡å‹
            if compile:
                logger.info("   ç¼–è¯‘æ¨¡å‹...")
                self.pipeline.transformer.compile()

            self.pipeline.set_progress_bar_config(disable=True)

        except ImportError:
            logger.error("âŒ diffusers æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install diffusers")
            raise

    def load_lora(self, lora_path: str, lora_strength: float = 1.0):
        """
        åŠ è½½ LoRA
        ä½¿ç”¨ fuse_lora æ–¹æ¡ˆï¼Œç®€å•å¯é ï¼Œé¿å… adapter å‘½åå†²çª

        Args:
            lora_path: LoRA æ–‡ä»¶è·¯å¾„
            lora_strength: LoRA å¼ºåº¦
        """
        if not lora_path or not lora_path.strip():
            return

        lora_path = lora_path.strip()
        lora_file = Path(lora_path)

        if not lora_file.exists():
            logger.warning(f"âš ï¸  LoRA æ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")
            return

        try:
            logger.info(f"ğŸ”§ åŠ è½½ LoRA: {lora_file.name}")
            logger.info(f"   å¼ºåº¦: {lora_strength}")

            # åŠ è½½ LoRA æƒé‡
            self.pipeline.load_lora_weights(str(lora_file.parent), weight_name=lora_file.name)

            # ä½¿ç”¨ fuse_lora ç›´æ¥èåˆåˆ°æ¨¡å‹æƒé‡ä¸­
            if hasattr(self.pipeline, 'fuse_lora'):
                self.pipeline.fuse_lora(lora_scale=lora_strength)
                logger.info(f"   âœ“ LoRA å·²èåˆåˆ°æ¨¡å‹ (å¼ºåº¦: {lora_strength})")
            else:
                logger.warning(f"âš ï¸  Pipeline ä¸æ”¯æŒ fuse_loraï¼ŒLoRA å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")

        except Exception as e:
            logger.error(f"   âŒ LoRA åŠ è½½å¤±è´¥: {e}")

    def unload_lora(self):
        """
        å¸è½½ LoRA
        å…ˆ unfuse æ¢å¤åŸå§‹æƒé‡ï¼Œå† unload é‡Šæ”¾ LoRA æƒé‡
        """
        try:
            # å…ˆ unfuse æ¢å¤åŸå§‹æ¨¡å‹æƒé‡
            if hasattr(self.pipeline, 'unfuse_lora'):
                self.pipeline.unfuse_lora()
                logger.info("âœ“ LoRA å·²ä»æ¨¡å‹ä¸­è§£é™¤èåˆ")

            # å† unload é‡Šæ”¾ LoRA æƒé‡
            if hasattr(self.pipeline, 'unload_lora_weights'):
                self.pipeline.unload_lora_weights()
                logger.info("âœ“ LoRA æƒé‡å·²å¸è½½")

        except Exception as e:
            logger.warning(f"âš ï¸  LoRA å¸è½½å¤±è´¥: {e}")

    def generate_progressive(
        self,
        positive_prompt: str,
        negative_prompt: str = "",
        trigger_word: str = "",
        # é˜¶æ®µé…ç½®
        stage1_size: Tuple[int, int] = (512, 672),  # åŸºç¡€ç”Ÿæˆå°ºå¯¸
        stage2_size: Tuple[int, int] = (640, 832),  # ä¸­é—´ç²¾ä¿®å°ºå¯¸
        stage3_size: Tuple[int, int] = (768, 1024), # æœ€ç»ˆè¾“å‡ºå°ºå¯¸
        # é‡‡æ ·å‚æ•°
        stage1_steps: int = 9,
        stage2_steps: int = 16,
        stage3_steps: int = 16,
        stage1_cfg: float = 2.0,
        stage2_cfg: float = 1.0,
        stage3_cfg: float = 1.0,
        # denoise å‚æ•°ï¼ˆç”¨äº img2imgï¼‰
        stage2_denoise: float = 0.7,
        stage3_denoise: float = 0.6,
        # LoRA å‚æ•°
        lora_path: str = "",
        lora_strength: float = 1.0,
        # ç§å­
        seeds: Optional[Tuple[int, int, int]] = None,
    ) -> Image.Image:
        """
        ä¸‰é˜¶æ®µæ¸è¿›å¼ç”Ÿæˆï¼ˆæ¨¡æ‹Ÿ ComfyUI workflowï¼‰

        Args:
            positive_prompt: æ­£å‘æç¤ºè¯
            negative_prompt: è´Ÿå‘æç¤ºè¯ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
            trigger_word: LoRA è§¦å‘è¯ï¼ˆå¦‚ "Deedeemegadoodo photo"ï¼‰
            stage1_size: é˜¶æ®µ1å°ºå¯¸ï¼ˆåŸºç¡€ç”Ÿæˆï¼‰
            stage2_size: é˜¶æ®µ2å°ºå¯¸ï¼ˆä¸­é—´ç²¾ä¿®ï¼‰
            stage3_size: é˜¶æ®µ3å°ºå¯¸ï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰
            stage1_steps: é˜¶æ®µ1æ­¥æ•°
            stage2_steps: é˜¶æ®µ2æ­¥æ•°
            stage3_steps: é˜¶æ®µ3æ­¥æ•°
            stage1_cfg: é˜¶æ®µ1 CFG
            stage2_cfg: é˜¶æ®µ2 CFG
            stage3_cfg: é˜¶æ®µ3 CFG
            stage2_denoise: é˜¶æ®µ2é‡ç»˜å¼ºåº¦
            stage3_denoise: é˜¶æ®µ3é‡ç»˜å¼ºåº¦
            lora_path: LoRA è·¯å¾„
            lora_strength: LoRA å¼ºåº¦
            seeds: ä¸‰ä¸ªé˜¶æ®µçš„éšæœºç§å­ï¼ˆNone=è‡ªåŠ¨ç”Ÿæˆï¼‰

        Returns:
            PIL.Image å¯¹è±¡
        """
        # åˆå¹¶ trigger word åˆ° prompt
        if trigger_word:
            full_prompt = f"{trigger_word}, {positive_prompt}"
        else:
            full_prompt = positive_prompt

        # ç”Ÿæˆç§å­
        if seeds is None:
            seeds = (
                torch.randint(0, 2**63 - 1, (1,)).item(),
                torch.randint(0, 2**63 - 1, (1,)).item(),
                torch.randint(0, 2**63 - 1, (1,)).item(),
            )

        # åŠ è½½ LoRAï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if lora_path:
            self.load_lora(lora_path, lora_strength)

        logger.info(f"ğŸ¨ ä¸‰é˜¶æ®µæ¸è¿›å¼ç”Ÿæˆ")
        logger.info(f"   Trigger Word: {trigger_word if trigger_word else '(æ— )'}")
        logger.info(f"   LoRA: {Path(lora_path).name if lora_path else '(æ— )'}")

        # ============ é˜¶æ®µ1ï¼šä½åˆ†è¾¨ç‡åŸºç¡€ç”Ÿæˆ ============
        logger.info(f"\nğŸ“ é˜¶æ®µ1: åŸºç¡€ç”Ÿæˆ {stage1_size[0]}Ã—{stage1_size[1]}")
        logger.info(f"   Steps: {stage1_steps}, CFG: {stage1_cfg}, Seed: {seeds[0]}")

        generator1 = torch.Generator(self.device).manual_seed(seeds[0])
        image_stage1 = self.pipeline(
            prompt=full_prompt,
            negative_prompt=negative_prompt if negative_prompt else None,
            height=stage1_size[1],
            width=stage1_size[0],
            num_inference_steps=stage1_steps,
            guidance_scale=stage1_cfg,
            generator=generator1
        ).images[0]

        # ============ é˜¶æ®µ2ï¼šä¸Šé‡‡æ ·åˆ°ä¸­åˆ†è¾¨ç‡ ============
        logger.info(f"\nğŸ“ é˜¶æ®µ2: ä¸­é—´ç²¾ä¿® {stage2_size[0]}Ã—{stage2_size[1]}")
        logger.info(f"   Steps: {stage2_steps}, CFG: {stage2_cfg}, Denoise: {stage2_denoise}, Seed: {seeds[1]}")

        # ä¸Šé‡‡æ ·
        image_upscaled2 = image_stage1.resize(stage2_size, Image.LANCZOS)

        # img2img ç²¾ä¿®
        generator2 = torch.Generator(self.device).manual_seed(seeds[1])
        image_stage2 = self.pipeline(
            prompt=full_prompt,
            negative_prompt=negative_prompt if negative_prompt else None,
            image=image_upscaled2,
            strength=stage2_denoise,  # denoise å¼ºåº¦
            num_inference_steps=stage2_steps,
            guidance_scale=stage2_cfg,
            generator=generator2
        ).images[0]

        # ============ é˜¶æ®µ3ï¼šä¸Šé‡‡æ ·åˆ°é«˜åˆ†è¾¨ç‡ ============
        logger.info(f"\nğŸ“ é˜¶æ®µ3: æœ€ç»ˆç²¾ä¿® {stage3_size[0]}Ã—{stage3_size[1]}")
        logger.info(f"   Steps: {stage3_steps}, CFG: {stage3_cfg}, Denoise: {stage3_denoise}, Seed: {seeds[2]}")

        # ä¸Šé‡‡æ ·
        image_upscaled3 = image_stage2.resize(stage3_size, Image.LANCZOS)

        # img2img ç²¾ä¿®
        generator3 = torch.Generator(self.device).manual_seed(seeds[2])
        image_final = self.pipeline(
            prompt=full_prompt,
            negative_prompt=negative_prompt if negative_prompt else None,
            image=image_upscaled3,
            strength=stage3_denoise,  # denoise å¼ºåº¦
            num_inference_steps=stage3_steps,
            guidance_scale=stage3_cfg,
            generator=generator3
        ).images[0]

        # å¸è½½ LoRAï¼ˆé¿å…å½±å“ä¸‹ä¸€æ¬¡ç”Ÿæˆï¼‰
        if lora_path:
            self.unload_lora()

        logger.info(f"\nâœ… ä¸‰é˜¶æ®µç”Ÿæˆå®Œæˆ")

        return image_final

    def generate_simple(
        self,
        positive_prompt: str,
        negative_prompt: str = "",
        trigger_word: str = "",
        width: int = 768,
        height: int = 1024,
        steps: int = 9,
        cfg: float = 1.0,
        seed: int = None,
        lora_path: str = "",
        lora_strength: float = 1.0
    ) -> Image.Image:
        """
        ç®€å•å•é˜¶æ®µç”Ÿæˆï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼Œå…¼å®¹åŸæœ‰æ¥å£ï¼‰

        Args:
            positive_prompt: æ­£å‘æç¤ºè¯
            negative_prompt: è´Ÿå‘æç¤ºè¯
            trigger_word: LoRA è§¦å‘è¯
            width: å®½åº¦
            height: é«˜åº¦
            steps: æ¨ç†æ­¥æ•°
            cfg: CFG scale
            seed: éšæœºç§å­
            lora_path: LoRA è·¯å¾„
            lora_strength: LoRA å¼ºåº¦

        Returns:
            PIL.Image å¯¹è±¡
        """
        # åˆå¹¶ trigger word åˆ° prompt
        if trigger_word:
            full_prompt = f"{trigger_word}, {positive_prompt}"
        else:
            full_prompt = positive_prompt

        # ç”Ÿæˆç§å­
        if seed is None:
            seed = torch.randint(0, 2**63 - 1, (1,)).item()

        # åŠ è½½ LoRAï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if lora_path:
            self.load_lora(lora_path, lora_strength)

        # åˆ›å»º generator
        generator = torch.Generator(self.device).manual_seed(seed)

        # å•é˜¶æ®µç”Ÿæˆ
        result = self.pipeline(
            prompt=full_prompt,
            negative_prompt=negative_prompt if negative_prompt else None,
            height=height,
            width=width,
            num_inference_steps=steps,
            guidance_scale=cfg,
            generator=generator
        )
        image = result.images[0]

        # å¸è½½ LoRAï¼ˆé¿å…å½±å“ä¸‹ä¸€æ¬¡ç”Ÿæˆï¼‰
        if lora_path:
            self.unload_lora()

        return image


# ============ æ‰¹é‡ç”Ÿæˆå‡½æ•° ============

async def generate_batch_images_advanced(
    tweets_batch: Dict,
    output_dir: str,
    model_path: str,
    device: str = "cuda",
    use_progressive: bool = True,
    negative_prompt_template: str = "",
    start_slot: int = 0,
    max_images: Optional[int] = None,
) -> List[Dict]:
    """
    ä½¿ç”¨é«˜çº§ç”Ÿæˆå™¨æ‰¹é‡ç”Ÿæˆå›¾ç‰‡

    Args:
        tweets_batch: æ¨æ–‡æ‰¹æ¬¡ JSON
        output_dir: è¾“å‡ºç›®å½•
        model_path: Z-Image æ¨¡å‹è·¯å¾„
        device: è®¾å¤‡
        use_progressive: æ˜¯å¦ä½¿ç”¨æ¸è¿›å¼ç”Ÿæˆï¼ˆTrue=æ–°æ–¹æ¡ˆï¼ŒFalse=å¤‡ç”¨æ–¹æ¡ˆï¼‰
        negative_prompt_template: è´Ÿå‘æç¤ºè¯æ¨¡æ¿ï¼ˆå¯é€‰ï¼Œæ”¯æŒä¸­æ–‡ï¼‰
        start_slot: èµ·å§‹ slot
        max_images: æœ€å¤§ç”Ÿæˆæ•°é‡

    Returns:
        ç”Ÿæˆç»“æœåˆ—è¡¨
    """
    generator = ZImageGeneratorAdvanced(model_path=model_path, device=device)

    tweets = tweets_batch["tweets"]
    persona_name = tweets_batch["persona"]["name"]
    day_offset = tweets_batch.get("daily_plan", {}).get("day_offset", None)
    total = len(tweets)
    end_slot = min(total, start_slot + max_images) if max_images else total

    logger.info(f"ğŸ“Š é«˜çº§æ‰¹é‡ç”Ÿæˆ")
    logger.info(f"   äººè®¾: {persona_name}")
    logger.info(f"   èŒƒå›´: slot {start_slot} ~ {end_slot-1}")
    logger.info(f"   æ¨¡å¼: {'æ¸è¿›å¼ç”Ÿæˆ (ä¼˜åŒ–)' if use_progressive else 'å•é˜¶æ®µç”Ÿæˆ (å¤‡ç”¨)'}")

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    results = []

    for i in range(start_slot, end_slot):
        tweet = tweets[i]
        img_gen = tweet["image_generation"]

        # æå–å‚æ•°
        positive_prompt = img_gen.get("positive_prompt", "")
        negative_prompt = img_gen.get("negative_prompt", negative_prompt_template)

        # Trigger Wordï¼ˆä» persona æˆ– img_gen ä¸­è·å–ï¼‰
        trigger_word = img_gen.get("trigger_word", "")
        if not trigger_word and "extensions" in tweets_batch.get("persona", {}):
            trigger_word = tweets_batch["persona"]["extensions"].get("trigger_word", "")

        # LoRA å‚æ•°
        lora_params = img_gen.get("lora_params", {})
        lora_path = lora_params.get("model_path", "")
        lora_strength = lora_params.get("strength", 1.0)

        # ç”Ÿæˆå‚æ•°
        gen_params = img_gen.get("generation_params", {})
        width = gen_params.get("width", 768)
        height = gen_params.get("height", 1024)
        steps = gen_params.get("steps", 9)
        cfg = gen_params.get("cfg", 1.0)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if day_offset is not None:
            filename = f"{persona_name}_day{day_offset}_slot{i}_{timestamp}.png"
        else:
            filename = f"{persona_name}_slot{i}_{timestamp}.png"
        output_path = output_dir / filename

        logger.info(f"\nğŸ¨ ç”Ÿæˆ slot {i+1}/{total}: {tweet['topic_type']}")

        try:
            if use_progressive:
                # æ¸è¿›å¼ç”Ÿæˆï¼ˆæ–°æ–¹æ¡ˆï¼‰
                image = generator.generate_progressive(
                    positive_prompt=positive_prompt,
                    negative_prompt=negative_prompt,
                    trigger_word=trigger_word,
                    stage3_size=(width, height),  # æœ€ç»ˆå°ºå¯¸
                    lora_path=lora_path,
                    lora_strength=lora_strength
                )
            else:
                # å•é˜¶æ®µç”Ÿæˆï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                image = generator.generate_simple(
                    positive_prompt=positive_prompt,
                    negative_prompt=negative_prompt,
                    trigger_word=trigger_word,
                    width=width,
                    height=height,
                    steps=steps,
                    cfg=cfg,
                    lora_path=lora_path,
                    lora_strength=lora_strength
                )

            # ä¿å­˜
            image.save(output_path)

            results.append({
                "slot": i,
                "status": "success",
                "output_path": str(output_path),
                "tweet_text": tweet["tweet_text"],
                "generation_mode": "progressive" if use_progressive else "simple"
            })

            logger.info(f"   âœ“ ä¿å­˜è‡³: {output_path}")

        except Exception as e:
            logger.error(f"   âŒ å¤±è´¥: {e}")
            results.append({
                "slot": i,
                "status": "failed",
                "error": str(e)
            })

    return results

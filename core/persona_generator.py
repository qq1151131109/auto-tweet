"""
Standalone Persona Generator
ç‹¬ç«‹äººè®¾ç”Ÿæˆå™¨ - å®Œå…¨å¤åˆ¶ComfyUIç²¾è°ƒé€»è¾‘
"""
import asyncio
import json
import base64
import io
from pathlib import Path
from typing import Dict, Optional
from PIL import Image
import sys

# æ·»åŠ è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.llm_client import AsyncLLMClient
from utils.json_parser import parse_llm_json_response
from prompts.core_generation_prompt import (
    get_core_generation_system_prompt,
    get_core_generation_user_prompt
)


class PersonaGenerator:
    """
    å®Œæ•´çš„äººè®¾ç”Ÿæˆå™¨
    å®Œå…¨ä¿ç•™ComfyUIçš„å¤šé˜¶æ®µç”Ÿæˆæµç¨‹å’Œç²¾è°ƒprompts
    """

    def __init__(self, llm_client: AsyncLLMClient):
        self.llm = llm_client

    async def generate_from_image(
        self,
        image_path: str,
        nsfw_level: str = "enabled",
        language: str = "English",
        location: str = "",
        business_goal: str = "",
        custom_instructions: str = "",
        temperature: float = 0.85
    ) -> Dict:
        """
        ä»å›¾ç‰‡ç”Ÿæˆå®Œæ•´äººè®¾ï¼ˆå¤šé˜¶æ®µæµç¨‹ï¼‰
        å®Œå…¨ä¿ç•™ComfyUIçš„PersonaCoreGeneratoré€»è¾‘

        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            nsfw_level: "disabled" æˆ– "enabled"
            language: "English" æˆ– "ä¸­æ–‡"
            location: åœ°ç†ä½ç½®ï¼ˆç•™ç©ºè‡ªåŠ¨ç”Ÿæˆï¼‰
            business_goal: ä¸šåŠ¡ç›®æ ‡
            custom_instructions: è‡ªå®šä¹‰æ§åˆ¶è¯
            temperature: æ¸©åº¦å‚æ•°

        Returns:
            å®Œæ•´çš„äººè®¾JSONï¼ˆSillyTavern Character Card V2æ ¼å¼ï¼‰
        """
        print(f"\n{'='*70}")
        print(f"ğŸ—ï¸  PersonaGenerator: Generating complete persona from image")
        print(f"    âœ¨ Multi-stage generation withç²¾è°ƒ prompts")
        print(f"{'='*70}\n")

        # Stage 1: Core Persona Generationï¼ˆæ ¸å¿ƒäººè®¾ç”Ÿæˆï¼‰
        print("ğŸ“ Stage 1: Generating core persona...")
        core_persona = await self._generate_core_persona(
            image_path, nsfw_level, language, location,
            business_goal, custom_instructions, temperature
        )

        # Stage 2: Tweet Strategy Generationï¼ˆæ¨æ–‡ç­–ç•¥ç”Ÿæˆï¼‰
        print("\nğŸ“ Stage 2: Generating tweet strategy...")
        strategy = await self._generate_tweet_strategy(core_persona, temperature)

        # Stage 3: Example Tweets Generationï¼ˆç¤ºä¾‹æ¨æ–‡ç”Ÿæˆï¼‰
        print("\nğŸ“ Stage 3: Generating example tweets...")
        tweets = await self._generate_example_tweets(
            core_persona, strategy, num_tweets=8, temperature=0.9
        )

        # âš¡ Stage 4-7: å¹¶å‘ç”Ÿæˆï¼ˆè¿™äº›é˜¶æ®µåªä¾èµ–core_personaï¼Œäº’ç›¸ç‹¬ç«‹ï¼‰
        print("\nâš¡ Stage 4-7: Parallel generation (social, authenticity, visual, knowledge)...")

        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        stage_4_task = self._generate_social_network(core_persona, temperature=0.85)
        stage_5_task = self._generate_authenticity(core_persona, temperature=0.8)
        stage_6_task = self._extract_visual_profile(core_persona, temperature=0.8)
        stage_7_task = self._generate_character_book(core_persona, num_entries=6, temperature=0.8)

        # ğŸš€ å¹¶å‘æ‰§è¡Œ Stage 4-7
        results = await asyncio.gather(
            stage_4_task,
            stage_5_task,
            stage_6_task,
            stage_7_task,
            return_exceptions=True
        )

        # è§£åŒ…ç»“æœ
        social_data = results[0] if not isinstance(results[0], Exception) else {}
        authenticity = results[1] if not isinstance(results[1], Exception) else {}
        visual_profile = results[2] if not isinstance(results[2], Exception) else {}
        character_book = results[3] if not isinstance(results[3], Exception) else {}

        # æ£€æŸ¥é”™è¯¯
        for i, result in enumerate(results, start=4):
            if isinstance(result, Exception):
                print(f"  âš ï¸  Stage {i} failed: {result}")

        print("  âœ“ Parallel stages completed")

        # Final Stage: Merge All Componentsï¼ˆåˆå¹¶æ‰€æœ‰ç»„ä»¶ï¼‰
        print("\nğŸ“ Final Stage: Merging all components...")
        complete_persona = self._merge_persona_components(
            core_persona, tweets, social_data, authenticity,
            visual_profile, character_book
        )

        print(f"\nâœ… Persona generation complete!")
        print(f"   Name: {complete_persona['data']['name']}")
        print(f"   Total tweet examples: {len(complete_persona['data'].get('twitter_persona', {}).get('tweet_examples', []))}")
        print(f"{'='*70}\n")

        return complete_persona

    def _image_to_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64"""
        with Image.open(image_path) as img:
            buffered = io.BytesIO()
            img.save(buffered, format="PNG")
            img_bytes = buffered.getvalue()
            return base64.b64encode(img_bytes).decode('utf-8')

    async def _generate_core_persona(
        self,
        image_path: str,
        nsfw_level: str,
        language: str,
        location: str,
        business_goal: str,
        custom_instructions: str,
        temperature: float
    ) -> Dict:
        """
        Stage 1: æ ¸å¿ƒäººè®¾ç”Ÿæˆ
        å®Œå…¨ä¿ç•™ComfyUI PersonaCoreGeneratorçš„prompté€»è¾‘
        """
        # è½¬æ¢å›¾åƒä¸ºbase64
        base64_image = self._image_to_base64(image_path)
        image_url = f"data:image/png;base64,{base64_image}"

        # æ„å»ºbase_paramsï¼ˆå®Œå…¨ä¿ç•™ComfyUIé€»è¾‘ï¼‰
        base_params = {
            "nsfw_level": nsfw_level,
            "language": language,
            "location": location if location.strip() else "è¯·è‡ªåŠ¨ç”Ÿæˆåˆé€‚çš„åœ°ç†ä½ç½®",
            "business_goal": business_goal,
            "custom_instructions": custom_instructions
        }

        # ä½¿ç”¨ç²¾è°ƒçš„promptsï¼ˆä»prompts/core_generation_prompt.pyï¼‰
        system_prompt = get_core_generation_system_prompt(language)
        appearance_analysis = "Analyze the appearance in the provided image carefully."
        user_prompt = get_core_generation_user_prompt(appearance_analysis, base_params)

        # è°ƒç”¨LLMï¼ˆæ”¯æŒvisionï¼‰
        messages = [
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=4000
        )

        # è§£æJSONï¼ˆå®Œå…¨ä¿ç•™ComfyUIçš„è§£æé€»è¾‘ï¼‰
        core_persona = self._parse_json_response(response)

        return core_persona

    async def _generate_tweet_strategy(
        self,
        core_persona: Dict,
        temperature: float
    ) -> Dict:
        """
        Stage 2: æ¨æ–‡ç­–ç•¥ç”Ÿæˆ
        å®Œå…¨ä¿ç•™ComfyUI PersonaTweetStrategyGeneratorçš„é€»è¾‘
        """
        data = core_persona.get('data', {})

        system_prompt = """You are a social media strategy expert specializing in authentic content planning.

Create a CUSTOM content strategy that matches this persona's unique characteristics, NOT generic categories.

CRITICAL: Analyze the persona's personality, tags, and background to derive SPECIFIC content types that fit THEM.

Output ONLY valid JSON, no markdown blocks."""

        user_prompt = f"""Create a custom content strategy for this persona:

CHARACTER:
Name: {data.get('name', '')}
Tags: {', '.join(data.get('tags', []))}
Personality: {data.get('personality', '')[:500]}
Description: {data.get('description', '')[:300]}

OUTPUT FORMAT:
{{
  "content_type_distribution": {{
    "custom_type_1": {{
      "weight": 0.25,
      "desc": "Description of what this type means for THIS persona"
    }},
    "custom_type_2": {{
      "weight": 0.20,
      "desc": "..."
    }}
    // 5-8 types total, weights sum to 1.0
  }}
}}

CRITICAL GUIDELINES:
1. Content types must be SPECIFIC to this persona, not generic
2. **IMPORTANT**: Mirror selfies (especially iPhone selfies in bathroom/bedroom) perform extremely well and should be heavily weighted (20-30%)
3. Include variations like:
   - "bathroom_mirror_selfie" or "bedroom_mirror_selfie" - showing off outfit/body
   - "gym_mirror_selfie" - post-workout physique shots
   - "fitting_room_selfie" - trying on clothes
4. Mirror selfies are versatile and work for almost any persona - they're casual, authentic, and high-engagement"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=8000
        )

        return self._parse_json_response(response)

    async def _generate_example_tweets(
        self,
        core_persona: Dict,
        strategy: Dict,
        num_tweets: int,
        temperature: float
    ) -> Dict:
        """
        Stage 3: ç”Ÿæˆç¤ºä¾‹æ¨æ–‡
        å®Œå…¨ä¿ç•™ComfyUI PersonaTweetGeneratorçš„é€»è¾‘
        """
        data = core_persona.get('data', {})

        # è¿™é‡Œä½¿ç”¨tweet_generation_prompt.pyä¸­çš„prompts
        from prompts.tweet_generation_prompt import (
            get_tweet_generation_system_prompt,
            get_tweet_generation_user_prompt
        )

        system_prompt = get_tweet_generation_system_prompt()
        user_prompt = get_tweet_generation_user_prompt(
            core_persona, num_tweets=num_tweets, strategy=strategy
        )

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=8000
        )

        # è§£ætweets array
        tweets_data = self._parse_json_response(response)

        # åŒ…è£…æˆtwitter_personaæ ¼å¼
        return {
            "twitter_persona": {
                "tweet_examples": tweets_data if isinstance(tweets_data, list) else tweets_data.get("tweets", [])
            }
        }

    async def _generate_social_network(
        self,
        core_persona: Dict,
        temperature: float
    ) -> Dict:
        """
        Stage 4: ç¤¾äº¤å…³ç³»ç”Ÿæˆ
        å®Œå…¨ä¿ç•™ComfyUI PersonaSocialGeneratorçš„é€»è¾‘
        """
        data = core_persona.get('data', {})

        system_prompt = """You are an expert at creating believable social networks for characters.

Create detailed, realistic relationships with:
1. Specific personalities and backgrounds for each person
2. Detailed stories of how they met and their history
3. Specific memories and shared experiences
4. Realistic interaction patterns and contact frequency
5. Natural conflicts, support, and dynamics

Output ONLY valid JSON, no markdown blocks.

CRITICAL: Each relationship should feel like a real person with depth, not a cardboard cutout."""

        user_prompt = f"""Create a detailed social network for this character:

CHARACTER:
Name: {data.get('name', '')}
Age: {data.get('core_info', {}).get('age', 23)}
Personality: {data.get('personality', '')[:500]}
Description: {data.get('description', '')[:300]}

REQUIRED OUTPUT:
{{
  "social_circle": {{
    "close_friends": [
      // 2-3 detailed friends with full backgrounds
    ],
    "past_relationships": [
      // 1-2 past romantic relationships with stories
    ],
    "online_friends": [
      // 2-3 online connections
    ]
  }}
}}

Each person needs: name, age, relation, personality, backstory, current_status, memorable_moments, interaction_pattern."""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=4000
        )

        return self._parse_json_response(response)

    async def _generate_authenticity(
        self,
        core_persona: Dict,
        temperature: float
    ) -> Dict:
        """
        Stage 5: çœŸå®æ„Ÿç³»ç»Ÿç”Ÿæˆ
        å®Œå…¨ä¿ç•™ComfyUI PersonaAuthenticityGeneratorçš„é€»è¾‘
        """
        data = core_persona.get('data', {})

        system_prompt = """You are an expert at making AI personas feel genuinely human and authentic.

Create strategic imperfections and authentic patterns that make this character feel REAL.

Output ONLY valid JSON, no markdown blocks."""

        user_prompt = f"""Create authenticity systems for this character:

CHARACTER:
Name: {data.get('name', '')}
Personality: {data.get('personality', '')[:500]}

OUTPUT:
{{
  "language_authenticity": {{
    "capitalization": {{"casual_lowercase_rate": 0.3}},
    "punctuation_style": {{"omit_final_period": 0.6}},
    "typo_patterns": {{"enabled": true, "base_rate": 0.1}},
    "filler_words": {{"usage_rate": 0.4}},
    "slang_and_abbreviations": {{"usage_rate": 0.5}}
  }},
  "strategic_flaws": {{
    "active_flaws": [
      {{
        "type": "sleep_deprived",
        "frequency": 0.2,
        "manifestations": ["..."]
      }}
    ]
  }}
}}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=3000
        )

        return self._parse_json_response(response)

    async def _extract_visual_profile(
        self,
        core_persona: Dict,
        temperature: float
    ) -> Dict:
        """
        Stage 6: è§†è§‰æ¡£æ¡ˆæå–
        å®Œå…¨ä¿ç•™ComfyUI PersonaVisualProfileExtractorçš„é€»è¾‘
        """
        data = core_persona.get('data', {})

        system_prompt = """Extract and organize visual elements for consistent image generation.

Create detailed outfit catalogs, pose guidelines, and atmosphere keywords.

Output ONLY valid JSON."""

        user_prompt = f"""Extract visual profile for:

CHARACTER:
Appearance: {data.get('appearance', {})}
Style: {data.get('appearance', {}).get('style', '')}

OUTPUT:
{{
  "visual_profile": {{
    "common_outfits": ["outfit descriptions..."],
    "common_props": ["props..."],
    "color_preferences": ["colors..."],
    "lighting_preferences": ["lighting setups..."],
    "typical_poses": ["pose descriptions..."],
    "atmosphere_keywords": ["moods..."],
    "camera_angles": ["angle descriptions..."]
  }}
}}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=2000
        )

        return self._parse_json_response(response)

    async def _generate_character_book(
        self,
        core_persona: Dict,
        num_entries: int,
        temperature: float
    ) -> Dict:
        """
        Stage 7: çŸ¥è¯†åº“ç”Ÿæˆ
        å®Œå…¨ä¿ç•™ComfyUI PersonaCharacterBookGeneratorçš„é€»è¾‘
        """
        data = core_persona.get('data', {})

        system_prompt = """Create a character knowledge base with deep contextual entries.

Each entry should provide rich context that deepens understanding of the character.

Output ONLY valid JSON."""

        user_prompt = f"""Create character book for:

CHARACTER:
Name: {data.get('name', '')}
Description: {data.get('description', '')[:500]}

Create {num_entries} knowledge entries about key aspects of their life.

OUTPUT:
{{
  "character_book": {{
    "entries": [
      {{
        "id": 1,
        "keys": ["keyword1", "keyword2"],
        "content": "Detailed contextual information...",
        "enabled": true
      }}
    ]
  }}
}}"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        response = await self.llm.generate(
            messages=messages,
            temperature=temperature,
            max_tokens=5000
        )

        return self._parse_json_response(response)

    def _merge_persona_components(
        self,
        core_persona: Dict,
        tweets: Dict,
        social_data: Dict,
        authenticity: Dict,
        visual_profile: Dict,
        character_book: Dict
    ) -> Dict:
        """
        Final Stage: åˆå¹¶æ‰€æœ‰ç»„ä»¶
        å®Œå…¨ä¿ç•™ComfyUI PersonaMergerçš„é€»è¾‘
        """
        # æ·±æ‹·è´core_persona
        import copy
        merged = copy.deepcopy(core_persona)

        # åˆå¹¶twitter_persona
        if "twitter_persona" in tweets:
            merged["data"]["twitter_persona"] = tweets["twitter_persona"]

        # åˆå¹¶social_circle
        if "social_circle" in social_data:
            merged["data"]["social_circle"] = social_data["social_circle"]

        # åˆå¹¶language_authenticityå’Œstrategic_flaws
        if "language_authenticity" in authenticity:
            merged["data"]["language_authenticity"] = authenticity["language_authenticity"]
        if "strategic_flaws" in authenticity:
            merged["data"]["strategic_flaws"] = authenticity["strategic_flaws"]

        # åˆå¹¶visual_profile
        if "visual_profile" in visual_profile:
            merged["data"]["visual_profile"] = visual_profile["visual_profile"]

        # åˆå¹¶character_book
        if "character_book" in character_book:
            merged["data"]["character_book"] = character_book["character_book"]

        return merged

    def _parse_json_response(self, response: str) -> Dict:
        """è§£æLLMè¿”å›çš„JSONï¼ˆä½¿ç”¨ç»Ÿä¸€çš„è§£æå·¥å…·ï¼‰"""
        return parse_llm_json_response(
            response,
            source_name="PersonaGenerator",
            enable_fallback=True
        )

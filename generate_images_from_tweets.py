#!/usr/bin/env python3
"""
ä»æ¨æ–‡æ‰¹æ¬¡ç”Ÿæˆå›¾ç‰‡ - ä½¿ç”¨native PyTorchå®ç°

ç›´æ¥è°ƒç”¨NativeImageGenerator,æ”¯æŒLoRA
"""
import sys
import os
import json
from pathlib import Path
import time
from typing import Optional, List, Dict

# å¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—å‰è®¾ç½®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

zimage_path = project_root / "Z-Image" / "src"
if zimage_path.exists():
    sys.path.insert(0, str(zimage_path))

from loguru import logger
from core.native_image_generator import NativeImageGenerator
from core.multi_gpu_image_generator import MultiGPUImageGenerator

logger.remove()
logger.add(sys.stderr, level="INFO")


def load_tweet_batch(filepath: str) -> dict:
    """åŠ è½½æ¨æ–‡æ‰¹æ¬¡"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def generate_images_for_batch(tweet_batch_path: str, num_gpus: int = 8):
    """
    ä¸ºä¸€ä¸ªæ¨æ–‡æ‰¹æ¬¡ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡

    Args:
        tweet_batch_path: æ¨æ–‡æ‰¹æ¬¡JSONæ–‡ä»¶è·¯å¾„
        num_gpus: ä½¿ç”¨çš„GPUæ•°é‡ (1=å•GPU, >1=å¤šGPUå¹¶è¡Œ)
    """
    logger.info(f"åŠ è½½æ¨æ–‡æ‰¹æ¬¡: {tweet_batch_path}")
    batch_data = load_tweet_batch(tweet_batch_path)

    persona_name = batch_data.get('persona', {}).get('name', 'unknown')
    lora_config = batch_data.get('persona', {}).get('lora', {})
    tweets = batch_data.get('tweets', [])

    logger.info(f"è§’è‰²: {persona_name}")
    logger.info(f"æ¨æ–‡æ•°é‡: {len(tweets)}")
    logger.info(f"LoRAé…ç½®: {lora_config}")

    # å¤„ç†LoRAè·¯å¾„
    lora_path = None
    lora_strength = 0.8
    if lora_config and lora_config.get('model_path'):
        lora_path = lora_config['model_path']
        lora_strength = lora_config.get('strength', 0.8)

        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if not os.path.isabs(lora_path):
            lora_path = os.path.join(project_root, lora_path)

        if not os.path.exists(lora_path):
            logger.warning(f"LoRAæ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")
            lora_path = None

    output_dir = Path("output_full_pipeline")
    output_dir.mkdir(exist_ok=True)

    # é€‰æ‹©å•GPUæˆ–å¤šGPUæ¨¡å¼
    if num_gpus > 1:
        logger.info(f"ğŸš€ ä½¿ç”¨å¤šGPUå¹¶è¡Œæ¨¡å¼ ({num_gpus} GPUs)")
        results = _generate_multi_gpu(
            tweets, persona_name, lora_path, lora_strength, output_dir, num_gpus
        )
    else:
        logger.info("ä½¿ç”¨å•GPUæ¨¡å¼")
        results = _generate_single_gpu(
            tweets, persona_name, lora_path, lora_strength, output_dir
        )

    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r['success'])
    failed_tweets = [(r['task_id'] + 1, r.get('error', 'Unknown')) for r in results if not r['success']]
    total_time = sum(r.get('elapsed', 0) for r in results)
    avg_time = total_time / success_count if success_count > 0 else 0

    logger.info(f"\nå®Œæˆ! æˆåŠŸ: {success_count}/{len(tweets)}, æ€»è€—æ—¶: {total_time:.1f}s, å¹³å‡: {avg_time:.1f}s/å¼ ")

    if failed_tweets:
        logger.warning(f"å¤±è´¥çš„æ¨æ–‡: {failed_tweets}")


def _generate_single_gpu(
    tweets: list,
    persona_name: str,
    lora_path: Optional[str],
    lora_strength: float,
    output_dir: Path
) -> List[Dict]:
    """å•GPUé¡ºåºç”Ÿæˆ"""
    generator = NativeImageGenerator()
    results = []

    # åŠ è½½LoRA
    lora_applied = False
    if lora_path:
        logger.info(f"åŠ è½½LoRA: {lora_path} (strength={lora_strength})")
        generator.lora_manager.load_lora(lora_path=lora_path, strength=lora_strength)
        lora_applied = True
        logger.success(f"âœ“ LoRAåŠ è½½æˆåŠŸ")

    try:
        for idx, tweet in enumerate(tweets, 1):
            image_gen = tweet.get('image_generation', {})
            scene_hint = image_gen.get('scene_hint', '')

            if not scene_hint:
                logger.warning(f"æ¨æ–‡ {idx} æ²¡æœ‰scene_hint,è·³è¿‡")
                results.append({'success': False, 'task_id': idx - 1, 'error': 'ç¼ºå°‘scene_hint'})
                continue

            logger.info(f"[{idx}/{len(tweets)}] ç”Ÿæˆå›¾ç‰‡...")

            start_time = time.time()

            try:
                # ç”Ÿæˆå›¾ç‰‡
                image = generator.generate(
                    prompt=scene_hint,
                    progressive=True,
                    seed=42 + idx
                )

                elapsed = time.time() - start_time

                # ä¿å­˜å›¾ç‰‡
                output_filename = f"{persona_name.replace(' ', '_')}_{idx:02d}.png"
                output_path = output_dir / output_filename
                image.save(output_path)

                logger.success(f"âœ“ å·²ä¿å­˜: {output_path} ({elapsed:.1f}s)")

                results.append({
                    'success': True,
                    'task_id': idx - 1,
                    'output_path': str(output_path),
                    'elapsed': elapsed
                })

            except Exception as e:
                elapsed = time.time() - start_time
                logger.error(f"âœ— å›¾ç‰‡ {idx} ç”Ÿæˆå¤±è´¥: {e}")
                results.append({
                    'success': False,
                    'task_id': idx - 1,
                    'error': str(e),
                    'elapsed': elapsed
                })

    finally:
        if lora_applied:
            logger.info("å¸è½½LoRA...")
            generator.lora_manager.unload_lora()

    return results


def _generate_multi_gpu(
    tweets: list,
    persona_name: str,
    lora_path: Optional[str],
    lora_strength: float,
    output_dir: Path,
    num_gpus: int
) -> List[Dict]:
    """å¤šGPUå¹¶è¡Œç”Ÿæˆ"""

    # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
    tasks = []
    for idx, tweet in enumerate(tweets, 1):
        image_gen = tweet.get('image_generation', {})
        scene_hint = image_gen.get('scene_hint', '')

        if not scene_hint:
            logger.warning(f"æ¨æ–‡ {idx} æ²¡æœ‰scene_hint,è·³è¿‡")
            continue

        output_filename = f"{persona_name.replace(' ', '_')}_{idx:02d}.png"
        output_path = str(output_dir / output_filename)

        tasks.append({
            'prompt': scene_hint,
            'lora_path': lora_path,
            'lora_strength': lora_strength,
            'seed': 42 + idx,
            'output_path': output_path
        })

    # ä½¿ç”¨å¤šGPUç”Ÿæˆå™¨
    with MultiGPUImageGenerator(num_gpus=num_gpus) as multi_gen:
        results = multi_gen.generate_batch(tasks)

    return results


def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python3 generate_images_from_tweets.py <tweet_batch_file> [num_gpus]")
        print("ç¤ºä¾‹: python3 generate_images_from_tweets.py output_full_pipeline/Arabella_Sinclair_tweets.json 8")
        sys.exit(1)

    tweet_batch_path = sys.argv[1]
    num_gpus = int(sys.argv[2]) if len(sys.argv) > 2 else 8

    logger.info("="*60)
    logger.info("å›¾ç‰‡ç”Ÿæˆ - Native PyTorch + LoRA")
    logger.info("="*60)
    logger.info(f"æ¨æ–‡æ‰¹æ¬¡: {tweet_batch_path}")
    logger.info(f"GPUæ•°é‡: {num_gpus}")
    logger.info("")

    generate_images_for_batch(tweet_batch_path, num_gpus)


if __name__ == "__main__":
    main()
